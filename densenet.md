# How to read papers
 Exercise Based on Stanford CS230 Autumn 2018

- This should take about 7 minutes.

## How to use?
Simply duplicate the template and start doing!

## Paper Name

Densely Connected Convolutional Networks

## Compile list of papers/medium articles/blogs

- 5 to 20 for research
- 50 to 100 for mastering the subject

## Take multiple pauses as described below
Read

### Title + Abstract + Figures

[x] Done

### Intro + Conclusion + Figures + Skim Rest  + Skip related work

[x] Done

### Read but skip/skip math

[x] Done

### Read but skips parts that don't make sense4

[x] Done

## make Skip around list ( 0 to 100%)

Read paper simultaneously.
eg;
- paper 1 you read say 10 20 %
- paper 2 seemed garbage
- paper 3 seemed worthy so you read it 100%
- paper 4 like 40% etc

## Questions to ask

1. What did authors tried to accomplish?

- solve gradient vanishing problem

1. What were the key elements of approach?

- form feed forward network but only with all consecutive/ahead layers.

1. What can you use yourself?

- I don't know bc i'm not working on cv task atm. Still I can say I will use the large versions for OD task.

1. What other references do you want to follow

- Resnet kept popping up so I will follow that and what is cifar


---

## How much did you read?

- Say around 40% but I got the idea what it is trying to do.Still skimmed the whole paper.
Basic is that this is a paper describing how densenet are better than resnet and handles vanishing gradient paper problem withit's uniqe architecture. Also shows off it's cifar sota scores and  how it is computationally efficient.
Also something about it's scalability.
